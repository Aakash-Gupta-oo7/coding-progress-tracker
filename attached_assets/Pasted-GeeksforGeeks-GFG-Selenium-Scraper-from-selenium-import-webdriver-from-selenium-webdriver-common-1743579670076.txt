GeeksforGeeks (GFG) Selenium Scraper
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import NoSuchElementException
import time
import json # To pretty-print the dictionary

def get_gfg_profile_selenium(username):
    """
    Fetches user profile details from GeeksforGeeks using Selenium.
    Targets the practice profile page.

    Args:
        username: The GFG username.

    Returns:
        A dictionary containing scraped profile details, or None if the profile
        cannot be accessed or a major scraping error occurs.
        Returns "N/A" for fields that couldn't be found.
    """
    # Common practice profile URL structure
    profile_url = f"https://auth.geeksforgeeks.org/user/{username}/practice"
    # Alternative URL sometimes seen, might need fallback logic if the above fails
    # profile_url = f"https://www.geeksforgeeks.org/user/{username}"

    # --- Selenium Setup ---
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    chrome_options.add_argument("--window-size=1920,1080")

    # --- IMPORTANT: Update this path to your ChromeDriver location ---
    try:
        # Assumes chromedriver is in your PATH or specify the service
        # service = Service('/path/to/your/chromedriver') # Example
        # driver = webdriver.Chrome(service=service, options=chrome_options)
        driver = webdriver.Chrome(options=chrome_options) # Use this if chromedriver is in PATH
    except Exception as e:
        print(f"Error initializing WebDriver: {e}")
        print("Please ensure ChromeDriver is installed and its path is correct or in system PATH.")
        return None

    profile_data = {"username": username, "profile_url": profile_url}

    try:
        print(f"Navigating to {profile_url}...")
        driver.get(profile_url)

        # --- Wait for page elements to load ---
        print("Waiting for page to load...")
        time.sleep(8) # Adjust this value if needed for GFG

        # --- Helper function to safely find elements ---
        def safe_find_text(driver, by, value, attribute=None):
            try:
                element = driver.find_element(by, value)
                if attribute:
                    return element.get_attribute(attribute)
                # Handle cases where text might be split across child elements
                text = element.text.strip()
                if not text: # If .text is empty, try getting text content attribute
                     text = element.get_attribute('textContent').strip()
                return text
            except NoSuchElementException:
                # print(f"Element not found using {by} = {value}") # Optional: for debugging
                return "N/A"

        # --- Scrape Basic Info ---
        print("Scraping basic info...")
        # Display Name (often in h4 or similar tag)
        profile_data['display_name'] = safe_find_text(driver, By.XPATH, "//div[contains(@class,'name')]") # Adjust if class changes
        if profile_data['display_name'] == 'N/A': # Fallback selector
             profile_data['display_name'] = safe_find_text(driver, By.XPATH, "//div[contains(@class,'user_name')]")

        # Institution (Look for label)
        profile_data['institution'] = safe_find_text(driver, By.XPATH, "//div[contains(text(), 'Institution')]/following-sibling::div")
        if profile_data['institution'] == 'N/A': # Fallback selector
            profile_data['institution'] = safe_find_text(driver, By.XPATH, "//i[contains(@class, 'fa-graduation-cap')]/parent::div/text()") # More fragile

        # --- Scrape Coding Scores & Ranks ---
        print("Scraping scores and ranks...")
        profile_data['overall_coding_score'] = safe_find_text(driver, By.XPATH, "//span[contains(text(),'Overall Coding Score')]/following-sibling::span")
        profile_data['problems_solved_count'] = safe_find_text(driver, By.XPATH, "//span[contains(text(),'Problems Solved')]/following-sibling::span")
        profile_data['monthly_coding_score'] = safe_find_text(driver, By.XPATH, "//span[contains(text(),'Monthly Coding Score')]/following-sibling::span")
        profile_data['current_streak'] = safe_find_text(driver, By.XPATH, "//span[contains(text(),'Current Streak')]/following-sibling::span")

        # --- Scrape Problems Solved by Difficulty ---
        print("Scraping problems solved by difficulty...")
        try:
            # Look for the container holding the difficulty bars/counts
            solved_container = driver.find_element(By.XPATH, "//div[contains(@class,'solved_problem_section')]") # This class name might change

            # Extract counts based on labels (More robust than specific div structures)
            profile_data['solved_easy'] = safe_find_text(solved_container, By.XPATH, ".//span[contains(text(),'Easy')]/following-sibling::span")
            profile_data['solved_medium'] = safe_find_text(solved_container, By.XPATH, ".//span[contains(text(),'Medium')]/following-sibling::span")
            profile_data['solved_hard'] = safe_find_text(solved_container, By.XPATH, ".//span[contains(text(),'Hard')]/following-sibling::span")

        except NoSuchElementException:
            print("Could not find solved problems by difficulty section.")
            profile_data.update({
                'solved_easy': "N/A",
                'solved_medium': "N/A",
                'solved_hard': "N/A"
            })

        # --- (Optional) Scrape Recently Solved Problems ---
        # This often requires finding a table or list structure which can vary
        # print("Scraping recently solved (if available)...")
        # recent_problems = []
        # try:
        #     problem_links = driver.find_elements(By.XPATH, "//div[contains(@class,'problem-list')]//a[contains(@href, 'problems')]") # Example selector
        #     for link in problem_links[:5]: # Limit
        #         recent_problems.append({
        #             "name": link.text.strip(),
        #             "url": link.get_attribute('href')
        #         })
        # except NoSuchElementException:
        #     print("Recent problems section not found or structure changed.")
        # profile_data['recently_solved'] = recent_problems


        print("Scraping finished.")

    except Exception as e:
        print(f"An error occurred during GFG scraping: {e}")
        # pass # Continue with potentially partial data
        return None # Return None on major error

    finally:
        print("Closing WebDriver.")
        if 'driver' in locals() and driver:
            driver.quit()

    return profile_data

# --- Main execution block for testing GFG ---
if __name__ == "__main__":
    # --- Replace with the GFG username you want to scrape ---
    target_gfg_username = "geeksforgeeks" # Example official account
    # target_gfg_username = "shivanigupta1_nov" # Example user

    print(f"\n--- Attempting to scrape GFG profile for: {target_gfg_username} ---")
    gfg_data = get_gfg_profile_selenium(target_gfg_username)

    if gfg_data:
        print("\n--- GFG Scraped Data ---")
        print(json.dumps(gfg_data, indent=4))
        print("----------------------\n")
    else:
        print(f"Could not retrieve GFG profile data for {target_gfg_username}.")

    print("GFG script finished.")
Use code with caution.
Python
